Входит в ТОП часто используемых алгоритмов [[data science]], [[Линейные модели]]

В отличие от обычной [[Регрессия|регрессии]] предсказывается значение вещественой переменной, а [[вероятность]] что объект относится к данному классу. Поэтому хоть и называется регрессией, родственна задачам классификации.

Основная идея в том, что пространство может быть линейно разделено на соответствующие классам области.
![[5553693449d97a6ccb730f4760a2eacd.png]]

Данная плоскость называется [[линейный дискриминант]]

На выходе мы получаем число от - до + бесконечности, обозначим его t
Нам нужно "конвертировать" этот диапазон в вероятность от 0 до 1, для этого используется [[Сигмоида]] (логистическая функция) (отсюда и название регрессии.)

$$P_+=\frac{e^t}{1+e^t}$$

Обучение: Рассмотрим g(x),количественная оценка что модель классифицирует правильно:

g(x) = $P_+$ - Если х часть класса "+"
g(x) = $1-P_+$ - Если х часть класса "+"

Таким образом, максимизируя g(x) обучаем модель.